server:
  port: 8017

spring:
  main:
    allow-bean-definition-overriding: true
  application:
    # 应用名称
    name: lr-data-rdcp-data-converge
  profiles:
    # 环境配置
    active: test

  # kafka 消费者设置
  kafka:
    producer:
      retries: 3
      batch-size: 1000
      linger-ms: 5
      buffer-memory: 33554432
      acks: 1
      maxBlock: 1
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      group-id: local-profile
    listener:
      type: SINGLE
    topic:
      cdc: cdc-data
      intelligence:
        fep-task: frontend-reschedule-test
        tunnel-datasource-change: tunnel-datasource-change-test
        original-structure: original-structure
      fep:
        ## listen
        xds-create: xds-create
        xds-update: xds-update
        upload-tableCount: upload-tableCount
        update-collect-message: update-collect-message
        upload-original-structure: upload-original-structure
        upload-original-table-count: upload-original-table-count
        upload-column-value: upload-column-value
        ## send
        ## tunnel-config-change-${ip}-${port} 按照前置机ip和端口区分
        tunnel-config-change: tunnel-config-change
        ## original-structure-config-${orgCode} 按照系统编码区分
        original-structure-config: original-structure-config
        ## tunnel-schedule-task-${ip}-${port} 按照前置机ip和端口区分
        tunnel-schedule-task: tunnel-schedule-task
        ## increment-sequence-${ip}-${port} 按照前置机ip和端口区分
        increment-sequence: increment-sequence
        fep-link: fep-link

  servlet:
    multipart:
      # 文件最大限制
      max-file-size: 1024MB
      # 请求最大限制
      max-request-size: 1024MB
      enabled: true
      # 设置文件缓存的临界点,超过则先保存到临时目录,默认为0,所有文件都会进行缓存
      file-size-threshold: 0

## ds配置
ds:
  host: http://172.16.29.60:12345/dolphinscheduler/

  switch: true

#MinIO对象存储，文件服务器
minio:
  endpoint: http://172.16.29.17:9001
  accessKey: exMYNZIl9mKJZWxN79HZ
  secretKey: iPrpcnsDn5k0zzd8HepbgMaYtn2H6hqURfPvZDOm
  bucketName: file-collect

## 消息队列可能的各种消息体key,用StrPool.COMMA(,)分割
message:
  body:
    ## 修改前的值
    prevalue: before
    ## 修改后的值
    postvalue: after
    ## 采集的表
    collectTable: table
    ## 动作
    operation: op
    ## 动作的代码
    insertOp: c
    updateOp: u
    deleteOp: d
    manageOp: management
  sql:
    ## sql模板的路径
    path: D:\sql.properties
    ## sql插入的后缀
    insertSuf: insert
    ## sql更新的后缀
    updateSuf: update
    ## sql删除的后缀
    deleteSuf: delete
    ## sql治理的后缀
    manageSuf: management

